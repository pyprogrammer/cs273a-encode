{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_lattice as tfl\n",
    "import re\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import functools\n",
    "import shutil\n",
    "from matplotlib import pyplot\n",
    "import multiprocessing as mp\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_path = \"../data/np_train/\"\n",
    "fasta_path = \"../data/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.gz\"\n",
    "model_dir = \"./model_cross/\"\n",
    "quantiles_dir = \"./quantiles_cross/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes = [f\"chr{i}\" for i in range(1, 23)] + [\"chrX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(window_size):\n",
    "    return range(-(window_size // 2), window_size // 2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cell_lines = 51\n",
    "cell_line_keypoints = 64\n",
    "num_assays = 35\n",
    "assay_keypoints = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"chr1    248956422\n",
    "chr2    242193529\n",
    "chr3    198295559\n",
    "chr4    190214555\n",
    "chr5    181538259\n",
    "chr6    170805979\n",
    "chr7    159345973\n",
    "chr8    145138636\n",
    "chr9    138394717\n",
    "chr10    133797422\n",
    "chr11    135086622\n",
    "chr12    133275309\n",
    "chr13    114364328\n",
    "chr14    107043718\n",
    "chr15    101991189\n",
    "chr16    90338345\n",
    "chr17    83257441\n",
    "chr18    80373285\n",
    "chr19    58617616\n",
    "chr20    64444167\n",
    "chr21    46709983\n",
    "chr22    50818468\n",
    "chrX    156040895\"\"\"\n",
    "chrom_length_map = {\n",
    "    k: int(v) for k, v in (line.split() for line in s.split(\"\\n\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_symbols = list(\"ACGTWSMKRYBDHVNZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = {}\n",
    "with gzip.open(fasta_path, \"rt\") as seq_file:\n",
    "    for seq in SeqIO.parse(seq_file, \"fasta\"):\n",
    "        references[seq.id] = seq.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val = -100.0\n",
    "\n",
    "def score_transform(s):\n",
    "    if np.isnan(s):\n",
    "        return missing_val\n",
    "#     return np.log(s + 1e-10)\n",
    "    # sigmoid transform to squish ends, centered about 0.05\n",
    "    return np.tanh(s + np.log(0.05))\n",
    "\n",
    "def find_value(arr, key):\n",
    "    ind = bisect.bisect_left(arr[\"f0\"], key)\n",
    "    if ind == len(arr):\n",
    "        return np.nan\n",
    "    l, h, v = arr[ind]\n",
    "    if l <= key < h:\n",
    "        return v\n",
    "    if l > key:\n",
    "        if ind > 0:\n",
    "            l, h, v = arr[ind - 1]\n",
    "            if l <= key < h:\n",
    "                return v\n",
    "    return np.nan\n",
    "\n",
    "def get_filename(line, assay, chrom):\n",
    "    return os.path.abspath(os.path.join(numpy_path, f\"{line}_{assay}_{chrom}.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_columns(window_size):\n",
    "    chrom = tf.feature_column.categorical_column_with_vocabulary_list(\"chr\", chromosomes)\n",
    "    assays = tf.feature_column.categorical_column_with_vocabulary_list(\"assay\", [str(i) for i in range(1, 36)])\n",
    "    lines = tf.feature_column.categorical_column_with_vocabulary_list(\"line\", [str(i) for i in range(1, 52)])\n",
    "    base_features = [\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(f\"base_{i}\", base_symbols)\n",
    "        for i in range(-(window_size // 2), window_size // 2 + 1)\n",
    "    ]\n",
    "    cell_features = [tf.feature_column.numeric_column(f\"C{i}\") for i in range(1, num_cell_lines+1)]\n",
    "    assay_features = [tf.feature_column.numeric_column(f\"M{i}\") for i in range(1, num_assays+1)]\n",
    "    return [chrom, assays, lines] + base_features + cell_features + assay_features\n",
    "\n",
    "def get_random_input(num_chrom_samples, sample_intervals, window_size):\n",
    "    fnames = random.choices(os.listdir(numpy_path), k=num_chrom_samples)\n",
    "    lines = []\n",
    "    chrs = []\n",
    "    assays = []\n",
    "    scores = []\n",
    "    bases = [[] for _ in range(window_size)]\n",
    "    cell_line_values = [[] for _ in range(num_cell_lines)]\n",
    "    assay_values = [[] for _ in range(num_assays)]\n",
    "    \n",
    "    \n",
    "    for fname in fnames:\n",
    "        line, assay, chrom = re.match(r\"(\\d+)_(\\d+)_(chr.+)\\.npy\", fname).groups()\n",
    "        arr = np.load(os.path.join(numpy_path, fname), mmap_mode=\"r\")\n",
    "        sampled = arr[np.random.choice(len(arr), sample_intervals)]\n",
    "        rel_centers = np.random.uniform(sample_intervals)\n",
    "        interval_centers = np.rint(sampled[\"f0\"] * rel_centers + (1 - rel_centers) * sampled[\"f1\"]).astype(np.int32)\n",
    "        clipped = np.clip(interval_centers, window_size // 2, chrom_length_map[chrom] - window_size // 2 - 1)\n",
    "        chrs.extend([chrom] * sample_intervals)\n",
    "        assays.extend([assay] * sample_intervals)\n",
    "        lines.extend([line] * sample_intervals)\n",
    "        for center, score in zip(clipped, sampled[\"f2\"]):\n",
    "            scores.append(score_transform(score))\n",
    "            subseq = references[chrom][center - window_size // 2: center + window_size//2 + 1]\n",
    "            for lst, char in zip(bases, subseq):\n",
    "                lst.append(char)\n",
    "        \n",
    "        for cell_line in range(1, num_cell_lines+1):\n",
    "            neighbor_filename = get_filename(cell_line, assay, chrom)\n",
    "            if cell_line == int(line, 10) or not os.path.exists(neighbor_filename):\n",
    "                values = [missing_val] * sample_intervals\n",
    "            else:\n",
    "                arr = np.load(neighbor_filename, mmap_mode=\"r\")\n",
    "                values = [score_transform(find_value(arr, center)) for center in clipped]\n",
    "            cell_line_values[cell_line-1].extend(values)\n",
    "        \n",
    "        for assay_id in range(1, num_assays+1):\n",
    "            neighbor_filename = get_filename(line, assay_id, chrom)\n",
    "            if assay_id == int(assay, 10) or not os.path.exists(neighbor_filename):\n",
    "                values = [missing_val] * sample_intervals\n",
    "            else:\n",
    "                arr = np.load(neighbor_filename, mmap_mode=\"r\")\n",
    "                values = [score_transform(find_value(arr, center)) for center in clipped]\n",
    "            assay_values[assay_id-1].extend(values)\n",
    "        \n",
    "    \n",
    "    cols = {\n",
    "        \"chr\": chrs,\n",
    "        \"assay\": assays,\n",
    "        \"scores\": scores,\n",
    "        \"line\": lines\n",
    "    }\n",
    "    for i, l in zip(range(-(window_size // 2), window_size // 2 + 1), bases):\n",
    "        cols[f\"base_{i}\"] = l\n",
    "    \n",
    "    cols.update({f\"C{i}\":cvs for i, cvs in enumerate(cell_line_values, start=1)})\n",
    "    cols.update({f\"M{i}\":avs for i, avs in enumerate(assay_values, start=1)})\n",
    "    \n",
    "    return pd.DataFrame(cols)\n",
    "\n",
    "def parallel_get_random_input(num_chrom_samples, sample_intervals, window_size):\n",
    "    chrom_par = min(8, num_chrom_samples)\n",
    "    interval_par = 1\n",
    "    with mp.Pool(chrom_par) as pool:\n",
    "        args = [(num_chrom_samples // chrom_par, sample_intervals // interval_par, window_size)]\n",
    "        args = args * chrom_par * interval_par\n",
    "        return pd.concat(pool.starmap(get_random_input, args), ignore_index=True)\n",
    "\n",
    "def get_input_fn(num_chrom_samples, sample_intervals, window_size, threads=16):\n",
    "    with pd.HDFStore(f\"train_65536_{window_size}.hdf\") as hdfs:\n",
    "        df = hdfs.get(random.choice(hdfs.keys()))\n",
    "#     df = parallel_get_random_input(num_chrom_samples, sample_intervals, window_size)\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df.drop(axis=1, columns=\"scores\"),\n",
    "        y=df.scores,\n",
    "        batch_size=len(df),\n",
    "        num_threads=threads,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 21\n",
    "num_chrom_samples = 4096\n",
    "sample_intervals = 16\n",
    "iterations = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parallel_get_random_input(num_chrom_samples, sample_intervals, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 16):\n",
    "    df = parallel_get_random_input(num_chrom_samples, sample_intervals, window_size)\n",
    "    df.to_hdf(\"train_65536_21.hdf\", key=f\"chunk_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
